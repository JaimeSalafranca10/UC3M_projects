head(probability)
prediction <- max.col(probability)
head(prediction)
prediction = predict(lda.model, newdata=dfTest)$class
head(prediction)
confusionMatrix(prediction, dfTest$Level)$table
confusionMatrix(prediction, dfTest$Level)$overall[1]
qda.model <- qda(Level ~ ., dfTrain,)
qda.model
qda.model <- qda(Level ~ ., dfTrain,)
obs <- max(table(dfTest$Level))
# Accuracy:
obs/nrow(dfTest)
# Hyper-parameters
control = rpart.control(minsplit = 30, maxdepth = 10, cp=0.01)
model = Level ~.
dtFit <- rpart(model, data=dfTrain, method = "class")
summary(dtFit)
rpart.plot(dtFit, digits=3)
control = rpart.control(minsplit = 40, maxdepth = 12, cp=0.001)
dtFit <- rpart(model, data=dfTrain, method = "class", control = control)
rpart.plot(dtFit, digits = 3)
dtPred <- predict(dtFit, dfTest, type = "class")
dtProb <- predict(dtFit, dfTest, type = "prob")
threshold = 0.2
dtProb <- prediction <- max.col(dtProb)
CM = confusionMatrix(factor(dtPred), dfTest$Level)$table
confusionMatrix(factor(dtPred), dfTest$Level)$overall[1]
cost = sum(as.vector(CM)*cost.unit)/sum(CM)
cost
caret.fit <- train(model,
data = dfTrain,
method = "rpart",
control=rpart.control(minsplit = 40, maxdepth = 12),
trControl = trainControl(method = "cv", number = 5),
tuneLength=10)
caret.fit
rpart.plot(caret.fit$finalModel)
dtProb <- predict(caret.fit, dfTest, type = "prob")
threshold = 0.2
dtProb <- prediction <- max.col(dtProb)
CM = confusionMatrix(factor(dtPred), dfTest$Level)$table
confusionMatrix(factor(dtPred), dfTest$Level)$overall[1]
cost
rf.train <- randomForest(Level ~., data=dfTrain,
ntree=200,mtry=6,importance=TRUE, do.trace=T)
rf.pred <- predict(rf.train, newdata=dfTest)
confusionMatrix(rf.pred, dfTest$Level)
```{r}
threshold = 0.2
gbmProb = predict(GBM.train, newdata=dfTest, n.trees=250, type="response")
dtPred3  <- max.col(gbmProb)
CM = confusionMatrix(factor(dtPred3), dfTest$Level)$table
confusionMatrix(factor(dtPred3), dfTest$Level)$overall[1]
ggplot(df) + aes(df$Risk, fill= df$Level) + geom_density(alpha=0.5) + facet_grid(~Level)+
labs(title="Risk of smokers by levels", x="Risk", fill0"Level")
ggplot(df) + aes(df$Risk, fill= df$Level) + geom_density(alpha=0.5) + facet_grid(~Level)+
labs(title="Risk of smokers by levels", x="Risk", fill="Level")
ggplot(df) + aes(x= Balanced.Diet, y = Obesity, fill= Level) + geom_tile() + labs(title="Diet and Obesity", x="Diet Level", y="Obesity", fill= "Level") + theme(legend.position="bottom")
ggplot(df) + aes(x = Level, y = Air.Pollution) * geom_violin()
ggplot(df) + aes(x = Level, y = Air.Pollution) + geom_violin()
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + geom_violin()
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + facet_wrap(~Genre)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + facet_grip(~Genre)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + facet_grid(~Genre)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + facet_grid(~Gender)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = Air.Pollution, fill = Level) + facet_wrap(~Gender)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y =OccuPational.Hazards fill = Level) + facet_wrap(~Gender)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = OccuPational.Hazards ,fill = Level) + facet_wrap(~Gender)+ geom_violin(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = OccuPational.Hazards ,fill = Level) + facet_wrap(~Gender)+ geom_boxplot(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = OccuPational.Hazards ,fill = Level) + geom_boxplot(position="dodge", alpha=0.5, outlier.colour="transparent")
ggplot(df) + aes(x = Level, y = OccuPational.Hazards ,fill = Level) + geom_boxplot(position="dodge", alpha=0.5, outlier.colour="black")
R = cor(df)   # correlation matrix
X = df[,-24]
X
R = cor(X)   # correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
library(corrplot)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
x1 = as.numeric(df$Level)
x1
x1 = as.numeric(df$Level)
R = cor(X)   # correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
X = cbin(X,x1)
X = cbind(X,x1)
R = cor(X)   # correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
X = df[,-24]
level = as.numeric(df$Level)
X = cbind(X,level)
R = cor(X)   # correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=0, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=90, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 2 #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 0.2 #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 0.2, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 2, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 1, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(R, method="color",
type="upper", order="hclust",
addCoef.col = NULL, # Add coefficient of correlation
tl.col="black", tl.srt=45, tl.cex = 0.6, #Text label color and rotation
# Combine with significance
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dfXTrain = X[spl,]
XTrain = X[spl,]
XTest = X[-spl,]
corr_delay <- sort(cor(XTrain[,c(2:25)])["TotalDelay",], decreasing = T)
corr_delay <- sort(cor(XTrain[,c(2:24)])["TotalDelay",], decreasing = T)
XTrain[,c(2:24)]
```{r}
corr_delay <- sort(cor(XTrain[,c(2:24)])["Risk",], decreasing = T)
corr=data.frame(corr_delay)
ggplot(corr,aes(x = row.names(corr), y = corr_delay)) +
geom_bar(stat = "identity", fill = "lightblue") +
scale_x_discrete(limits= row.names(corr)) +
labs(x = "", y = "risk", title = "Correlations") +
theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
axis.text.x = element_text(angle = 45, hjust = 1))
corr_delay <- sort(cor(XTrain[,c(2:22)])["Risk",], decreasing = T)
corr_delay <- sort(cor(XTrain[,c(2:22)])["Risk",], decreasing = T)
corr_delay <- sort(cor(XTrain[,c(2:24)])["Risk",], decreasing = T)
corr=data.frame(corr_delay)
ggplot(corr,aes(x = row.names(corr), y = corr_delay)) +
geom_bar(stat = "identity", fill = "lightblue") +
scale_x_discrete(limits= row.names(corr)) +
labs(x = "", y = "risk", title = "Correlations") +
theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
axis.text.x = element_text(angle = 45, hjust = 1))
linFit <- lm(log(Risk+10) ~ HistoricallyLate, data=XTrain)
summary(linFit)
linFit <- lm(Risk) ~ HistoricallyLate, data=XTrain)
linFit <- lm(Risk), data=XTrain)
summary(linFit)
logit.model <- glm(Risk ~ ., family=binomial(link='logit'), data=XTrain)
logit.model <- glm(Risk ~ ., family=binomial(link='logit'), data=scale(XTrain))
logit.model <- glmnet(as.matrix(Xtrain[,-1]),Xtrain$Risk, family=c("binomial"), alpha=0, lambda=0.01)
library(glmnet)
logit.model <- glmnet(as.matrix(Xtrain[,-1]),Xtrain$Risk, family=c("binomial"), alpha=0, lambda=0.01)
logit.model <- glmnet(as.matrix(XTrain[,-1]),Xrain$Risk, family=c("binomial"), alpha=0, lambda=0.01)
logit.model <- glmnet(as.matrix(XTrain[,-1]),XTrain$Risk, family=c("binomial"), alpha=0, lambda=0.01)
model <- lda(Risk ~ ., data=XTrain, prior = c(.9, .1))
model <- lda(Risk ~ ., data=XTrain)
linFit <- lm(log(Risk) ~Genetic.Risk), data=XTrain)
linFit <- lm(log(Risk) ~ Genetic.Risk, data=XTrain)
summary(linFit)
par(mfrow=c(2,2))
plot(linFit, pch=23 ,bg='orange',cex=2)
cor(XTest$Risk, pr.simple)^2
pr.simple = exp(predict(linFit, newdata=XTest))
cor(XTest$Risk, pr.simple)^2
linFit <- lm((Risk) ~ Genetic.Risk, data=XTrain)
summary(linFit)
pr.simple = exp(predict(linFit, newdata=XTest))
cor(XTest$Risk, pr.simple)^2
pr.simple = (predict(linFit, newdata=XTest))
cor(XTest$Risk, pr.simple)^2
linFit <- lm(Risk ~ Genetic.Risk + Occupational.Hazards + chronic.lung.disease + Obesity + , data=XTrain)
linFit <- lm(Risk ~ Genetic.Risk + Occupational.Hazards + chronic.lung.disease + Obesity  , data=XTrain)
linFit <- lm(Risk ~ Genetic.Risk + OccuPational.Hazards + chronic.lung.disease + Obesity  , data=XTrain)
linFit <- lm(Risk ~ Genetic.Risk + OccuPational.Hazards + chronic.ung.disease + Obesity  , data=XTrain)
linFit <- lm(Risk ~ Genetic.Risk + OccuPational.Hazards + chronic.Lung.disease + Obesity  , data=XTrain)
linFit <- lm(Risk ~ Genetic.Risk + OccuPational.Hazards + chronic.Lung.Disease + Obesity  , data=XTrain)
summary(linFit)
library(olsrr)
model = Risk ~ Genetic.Risk + OccuPational.Hazards + chronic.Lung.Disease + Obesity
linFit <- lm(model, data=XTrain)
ols_step_all_possible(linFit) # All possible subset regressions: the number is exponential with p
modelresult = ols_step_all_possible(linFit) # All possible subset regressions: the number is exponential with p
ols_step_best_subset(linFit
ols_step_best_subset(linFit)
ols_step_best_subset(linFit)
plot(ols_step_forward_p(linFit))
predictions <- predict(linFit, newdata=XTest)
cor(XTest$Risk, predictions)^2
RMSE <- sqrt(mean((predictions - XTest$Risk)^2))
RMSE
mean(XTrain$Risk)
mean(XTrain$Risk)
benchFit <- lm(Risk ~ 1, data=Xtrain)
benchFit <- lm(Risk ~ 1, data=XTrain)
benchFit$coefficients
predictions <- predict(benchFit, newdata=XTest)
RMSE <- sqrt(mean((predictions - testing$price)^2))
RMSE <- sqrt(mean((predictions - XTest$Risk)^2))
RMSE
ctrl <- trainControl(method = "repeatedcv",
number = 5, repeats = 1)
lm_tune <- train(ModelS, data = training,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune <- train(ModelS, data = XTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune <- train(model, data = XTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune
test_results$lm <- predict(lm_tune, XTest)
test_results <- data.frame(Risk = XTest$Risk)
lm_tune <- train(model, data = XTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune
test_results$lm <- predict(lm_tune, XTest)
postResample(pred = test_results$lm,  obs = test_results$Risk)
qplot(test_results$lm, test_results$Risk) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
test_results$Risk
test_results$lm
qplot(test_results$lm, test_results$Risk) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
qplot(test_results$lm, test_results$Risk) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 200), y = c(10,200)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
qplot(test_results$lm, test_results$Risk) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 200), y = c(40,100)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
qplot(test_results$lm, test_results$Risk) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(40, 100), y = c(40,100)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
for_tune <- train(ModelF, data = XTrain,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
for_tune <- train(model, data = XTrain,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
for_tune
for_tune <- train(model, data = XTrain,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
for_tune <- train(model, data = XTrain,
method = "leapForward",
preProc=c('scale', 'center'),
trControl = ctrl)
for_tune
plot(for_tune)
test_results$bw <- predict(back_tune, XTest)
postResample(pred = test_results$bw,  obs = test_results$Risk)
test_results$bw <- predict(back_tune, XTest)
test_results$bw <- predict(for_tune, XTest)
postResample(pred = test_results$bw,  obs = test_results$Risk)
qplot(test_results$bw, test_results$Risk) +
labs(title="Backward Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
qplot(test_results$bw, test_results$Risk) +
labs(title="Backward Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(40,100), y = c(40,100)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
lm_tune <- train(model, data = XTrain,
method = "lm",
preProc=c("scale", "center"),
trControl = ctrl)
test_results <- data.frame(Risk = XTest$Risk)
lm_tune <- train(model, data = XTrain,
method = "lm",
preProc=c("scale", "center"),
trControl = ctrl)
# X matrix
X = model.matrix(ModelF, data=XTrain)[,-1]  # skip column of ones
# X matrix
X = model.matrix(model, data=XTrain)[,-1]  # skip column of ones
# y variable
y = XTrain$Risk
grid = seq(0, .1, length = 100)  # a 100-size grid for lambda (rho in slides)
ridge.mod = glmnet(X, y, alpha=0, lambda=grid)  # alpha=0 for ridge regression
dim(coef(ridge.mod))
plot(ridge.mod, xvar="lambda")
ridge.cv = cv.glmnet(X, y, type.measure="mse", alpha=0)
plot(ridge.cv)
opt.lambda <- ridge.cv$lambda.min
opt.lambda
lambda.index <- which(ridge.cv$lambda == ridge.cv$lambda.1se)
beta.ridge <- ridge.cv$glmnet.fit$beta[, lambda.index]
beta.ridge
X.test = model.matrix(ModelF, data=testing)[,-1]  # skip column of ones
X.test = model.matrix(model, data=XTest)[,-1]  # skip column of ones
ridge.pred = predict(ridge.cv$glmnet.fit, s=opt.lambda, newx=X.test)
y.test =testing$price
y.test =XTest$price
postResample(pred = ridge.pred,  obs = y.test)
y.test =XTest$Risk
postResample(pred = ridge.pred,  obs = y.test)
# the grid for lambda
ridge_grid <- expand.grid(lambda = seq(0, .1, length = 100))
# train
ridge_tune <- train(ModelF, data = training,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
# train
ridge_tune <- train(model, data = XTrain,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
# train
ridge_tune <- train(model, data = XTrain,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
plot(ridge_tune)
plot(ridge_tune)
# prediction
test_results$ridge <- predict(ridge_tune, XTest)
postResample(pred = test_results$ridge,  obs = test_results$price)
postResample(pred = test_results$ridge,  obs = test_results$Risk)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 100))
lasso_tune <- train(ModelF, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_tune$bestTune
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 400))
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 400))
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_grid <- expand.grid(fraction = seq(.01, 10, length = 400))
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 400))
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
lasso_tune <- train(model, data = XTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_tune$bestTune
test_results$lasso <- predict(lasso_tune, XTest)
postResample(pred = test_results$lasso,  obs = test_results$price)
postResample(pred = test_results$lasso,  obs = test_results$Risk)
modelLookup('glmnet')
glmnet_tune <- train(ModelF, data = training,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
glmnet_tune <- train(ModelF, data = XTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
glmnet_tune <- train(model, data = XTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))
glmnet_tune <- train(model, data = XTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
glmnet_tune <- train(model, data = XTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
plot(glmnet_tune)
glmnet_tune$bestTune
postResample(pred = test_results$glmnet,  obs = test_results$Risk)
test_results$glmnet <- predict(glmnet_tune, XTest)
postResample(pred = test_results$glmnet,  obs = test_results$Risk)
modelLookup('kknn')
knn_tune <- train(model,
data = XTrain,
method = "kknn",
preProc=c('scale','center'),
tuneGrid = data.frame(kmax=c(11,13,15,19,21),distance=2,kernel='optimal'),
trControl = ctrl)
